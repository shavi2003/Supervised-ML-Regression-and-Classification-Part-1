{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba13f722",
   "metadata": {},
   "source": [
    "Hi there! This is Shavarsh Melikyan's gradient descent algorithm's implementation (multiple features). This algorithm was learnt through the ML specialization's \"Supervized Machine Learning\" (part 1: https://www.deeplearning.ai/program/machine-learning-specialization/) course; materials from week #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1762b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first of all, importing important and useful libraries\n",
    "import numpy as np\n",
    "import math, copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a71ec41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2104    5    1   45]\n",
      " [1416    3    2   40]\n",
      " [ 852    2    1   35]] [460 232 178]\n"
     ]
    }
   ],
   "source": [
    "#some arbitrary data of houses' sizes and their prices/bedrooms/rooms/floors\n",
    "\n",
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n",
    "\n",
    "print(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc375d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which defines a cost function (which we have to minimize by GD)\n",
    "\n",
    "def compute_cost(x, y, w, b):\n",
    "    m = x.shape[0] #number of examples\n",
    "    cost = 0\n",
    "    \n",
    "    \n",
    "    for i in range(m): #sum of differences' square\n",
    "        f_wb_i = np.dot(x, w) + b\n",
    "        cost = cost + (f_wb_i - y[i]) ** 2\n",
    "        \n",
    "    total_cost = cost / (2*m) \n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07ea3ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now writing the function for computing gradients (partial derivatives with respect to w and b of cost function J)\n",
    "\n",
    "def compute_gradient(x, y, w, b):\n",
    "    m, n = x.shape #number of examples\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0\n",
    "    \n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(x[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * x[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0934efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_init = 785.1811367994083\n",
    "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa37e8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w,b: -1.6739251122999121e-06\n",
      "dj_dw at initial w,b: \n",
      " [-2.72623574e-03 -6.27197255e-06 -2.21745574e-06 -6.92403377e-05]\n"
     ]
    }
   ],
   "source": [
    "#Compute and display gradient \n",
    "tmp_dj_db, tmp_dj_dw = compute_gradient(X_train, y_train, w_init, b_init)\n",
    "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
    "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f3cb916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function of the gradient descent which returns w, b and lists of cost function's values \n",
    "#and parameter lists ([w, b])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def gradient_descent(x, y, w_in, b_in, alpha, num_iters, cost_function, gradient_function):\n",
    "    \n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = copy.deepcopy(b_in)\n",
    "    dj_dw = 0\n",
    "    dj_db = 0\n",
    "    J_history = []\n",
    "    p_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        dj_dw, dj_db = gradient_function(x, y, w, b)\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "        \n",
    "        if i < 10000:\n",
    "            J_history.append(cost_function(x, y, w, b))\n",
    "            p_history.append([w, b])\n",
    "            \n",
    "        if i% math.ceil(num_iters/10) == 0:\n",
    "            print(f\"Iteration {i:4}: Cost {J_history[-1]:0.2e} \",\n",
    "                  f\"dj_dw: {dj_dw: 0.3e}, dj_db: {dj_db: 0.3e}  \",\n",
    "                  f\"w: {w: 0.3e}, b:{b: 0.5e}\")\n",
    "            \n",
    "    return w, b, J_history, p_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
